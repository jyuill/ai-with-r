---
title: "ChatBot to read in and analyze data from PDF"
format: html
---

```{r setup}
# load required packages
library(tidyverse)
library(ellmer)
library(pdftools)
```


An experiment in using LLMs to analyze data within R environment. Using the [BC Liquor Market Report](https://www.bcldb.com/files/Liquor_Market_Review_F24_25_Q4_March_2025.pdf), a pdf document with text and tables as example.

Inspired by/heavily leveraging [Harnessing LLMs for Data Analysis](https://www.youtube.com/watch?v=owDd1CJ17uQ&t=720s) YT video by Joe Cheng.

### Required

1.  A document with data to analyze - pdf in this case.
2.  R packages: ellmer, pdftools
3.  LLM vendor API key, stored in R environment (.Renviron)
4.  Selection of specific model to use.

### Import data doc & convert to markdown

Pre-processing for this example:

1.  Original document is PDF, over 30 pages long. A lot for LLM to digest with basic API privileges.
2.  For ease/economy, I used online PDF splitter to extract the page with Beer Net \$ sales table.
3.  **Convert to markdown**: examples in the video were markdown (.md) documents - presumably because they have more machine readable structure to them. I used advice from ChatGPT to import the pdf and convert to md.


```{r convert_pdf}
# uses pdftools pkg
pdf_text <- pdf_text("LMR_Mar_2025-beer-table.pdf")
writeLines(pdf_text, "LMR_beer.md")
```


Check md version


```{r check_md}
readLines("LMR_beer.md")
```


### Set up system prompt

Having the right system prompt sets the context for further prompting. In this case, the **md doc is integrated** into the system prompt.


```{r system_prompt}
# use markdown version of doc because easier for LLM to interpret
sys_prompt <- paste(
    "You are a bot that answers questions based on this Liquor Market Review report:",
    "<liquor_market_review>",
    readLines("LMR_beer.md"),
    "</liquor_market_review>",
    "* Cite report sections by category or page numbers.",
    collapse = "\n"
)
```


### Setup LLM client function

This sets the parameters for what type of model family to use, what specific model. API key will likely be needed for this:

1.  Set up account with preferred LLM vendor.
2.  Generate API key.
3.  Paste into .Renviron file using expected variable (eg. OPENAI_API_KEY=<key>)


```{r llm_client_function}
client <- chat_openai(system_prompt=sys_prompt,
model = "gpt-4o-mini"
)
```


### Run test prompt


```{r question_01}
# disable if just using bot in browser
#client$chat("What is the total net $ beer sales for FY2024/25 Q4?")
```


### Generate live session in browser

-   If you run the cell below individually, it will pop up an interactive window in the Viewer pane in Positron (will include the prompt above).
-   If you render the document with 'preview', it will open a browser window where you can interact with the LLM.
-   According to the info on the underlying quarto render, this is using shiny.

::: callout-caution
## warning: LLMs may not be reliable for data interpretation
:::


```{r launch_bot}
# disable until ready
live_browser(client)
```
